{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Haihui Pan\n",
    "Date: 2021-10-19\n",
    "Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch简介\n",
    "\n",
    "Torch是一个与Numpy类似的张量操作库，但是Torch可以支持GPU。Torch采用C语言作为底层，以Lua为上层接口的深度学习库。但是，由于Lua太小众化，因此才出现Pytorch。Pytorch使用与Torch相同的底层C语言库,但是上层的接口语言是Python。\n",
    "\n",
    "Pytorch是一个基于Torch的深度学习框架，主要由Facebook的人工智能研究小组开发的。PyTorch主要提供两个强大的功能：\n",
    "* 强大的GPU进行张量加速计算\n",
    "* 神经网络自动求导机制\n",
    "\n",
    "PyTorch优点：\n",
    "* 面向对象设计简洁优雅，容易入门\n",
    "* 有不错的技术文档，由Facebook进行维护"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor的基本类型\n",
    "Tensor的基本类型有5种：\n",
    "* 16位整型：torch.short\n",
    "* 32位整型：torch.int\n",
    "* 64位整型：torch.long\n",
    "* 32位浮点型：torch.float（默认）\n",
    "* 64位浮点型：torch.double\n",
    "\n",
    "除了数字类型外，还有byte和char类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#版本信息\n",
    "import torch\n",
    "torch.__version__\n",
    "\n",
    "device=\"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#从List进行初始化\n",
    "a=[1,2,3]\n",
    "print(torch.tensor(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#从numpy初始化\n",
    "import numpy as np\n",
    "\n",
    "np_data=np.array(a)\n",
    "np_data=torch.from_numpy(np_data)\n",
    "np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1291, 0.4987, 0.4681],\n",
       "        [0.8987, 0.5599, 0.1569]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机初始化\n",
    "x=torch.rand(2,3) #shape:(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用1来进行初始化\n",
    "x=torch.ones(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#单位矩阵初始化\n",
    "x=torch.eye(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor属性\n",
    "* shape:形状\n",
    "* dtype:类型\n",
    "* device:数据是存放在CPU还是GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t shape: torch.Size([2, 3])\n",
      "t dtype: torch.float32\n",
      "t device: cpu\n"
     ]
    }
   ],
   "source": [
    "t=torch.rand(2,3,dtype=torch.float)\n",
    "print(\"t shape:\",t.shape)\n",
    "print(\"t dtype:\",t.dtype)\n",
    "print(\"t device:\",t.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor常见操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#转numpy\n",
    "tensor=torch.eye(3,3)\n",
    "np_tensor=tensor.numpy()\n",
    "print(type(np_tensor),\"\\n\",np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一行： tensor([1., 0., 0.])\n",
      "第一列： tensor([1., 0., 0.])\n",
      "最后一列： tensor([0., 0., 1.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#切片(与Numpy一致)\n",
    "tensor=torch.eye(3,3)\n",
    "print(\"第一行：\",tensor[0])\n",
    "print(\"第一列：\",tensor[:,0])\n",
    "print(\"最后一列：\",tensor[:,-1])\n",
    "\n",
    "tensor[:,0]=0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5715, 0.9573, 0.0328],\n",
      "        [0.2425, 0.7956, 0.5219],\n",
      "        [0.6476, 0.5040, 0.2640]])\n",
      "max of dim:0\n",
      "tensor([0.6476, 0.9573, 0.5219])\n",
      "tensor([2, 0, 1])\n",
      "max of dim:1\n",
      "tensor([0.9573, 0.7956, 0.6476])\n",
      "tensor([1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# 取max\n",
    "t=torch.rand(3,3)\n",
    "print(t)\n",
    "max_value,max_idx=torch.max(t,dim=0) #max(t[i][0]),max(t[i][1]),max(t[i][2]) ,由于每个t[i]都是3维，因此相当于是比较每一列的最大值\n",
    "print(\"max of dim:0\")\n",
    "print(max_value)\n",
    "print(max_idx)\n",
    "\n",
    "print(\"max of dim:1\")\n",
    "max_value,max_idx=torch.max(t,dim=1) #max(t[0][i]),max(t[1][i]),max(t[2][i]) ,\n",
    "print(max_value)\n",
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum by dim:0\n",
      "tensor([6, 7, 8])\n",
      "sum by dim:1\n",
      "tensor([3, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "#sum中dim的取值与max为一致\n",
    "t=[[1,1,1],\n",
    "   [2,3,4],\n",
    "   [3,3,3]]\n",
    "t=torch.tensor(t)\n",
    "\n",
    "#效果相当于列相加\n",
    "print(\"sum by dim:0\")\n",
    "print(torch.sum(t,dim=0)) #sum(t[i])\n",
    "\n",
    "#效果相当于行相加\n",
    "print(\"sum by dim:1\")\n",
    "print(torch.sum(t,dim=1)) #sum(t[0][i]),sum(t[1][i]),sum(t[2][i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor矩阵操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "#矩阵转置\n",
    "a=[[1,2],\n",
    "   [3,4]]\n",
    "a=torch.tensor(a)\n",
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 1.],\n",
      "        [1., 2., 1.],\n",
      "        [1., 1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵相加\n",
    "t1=torch.eye(3,3)\n",
    "t2=torch.ones(3,3)\n",
    "\n",
    "print(t1+t2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵相乘\n",
    "t1=torch.ones(2,2)\n",
    "t2=torch.ones(2,2)\n",
    "\n",
    "#两种操作是等价\n",
    "print(t1.matmul(t2))\n",
    "print(t1@t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#矩阵相对应的位置相乘(element-wise product)\n",
    "t1=torch.ones(2,2)\n",
    "t2=torch.ones(2,2)\n",
    "\n",
    "#两种操作是等价的\n",
    "print(t1*t2)\n",
    "print(t1.mul(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor矩阵shape变更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "#view变换形状\n",
    "t=torch.rand(4,4)\n",
    "t=t.view(-1,2) #shape:(2,8)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "#更换维度（2,3,4）-> (3,2,4)\n",
    "t=torch.rand(2,3,4)\n",
    "t=t.transpose(0,1) #更换dim=0和dim=1的维度\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand\n",
    "t = torch.tensor([[1], [2], [3]]) #shape(3,1)\n",
    "t=t.expand(-1,4) # shape(3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor矩阵拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.tensor([1,2,3])\n",
    "t2=torch.tensor([1,2,3])\n",
    "\n",
    "print(torch.cat([t1,t2],dim=0)) #[t[0],t[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.tensor([1,2,3])\n",
    "t2=torch.tensor([1,2,3])\n",
    "\n",
    "#扩充维度\n",
    "t1=torch.unsqueeze(t1,dim=0)\n",
    "t2=torch.unsqueeze(t2,dim=0)\n",
    "\n",
    "print(torch.cat([t1,t2],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.eye(3,3)\n",
    "\n",
    "#按列进行拼接，逻辑与max一致[t1[0],t1[1],t2[2],t1[0],t1[1],t2[2],t1[0],t1[1],t2[2]]\n",
    "print(torch.cat([t1,t1,t1],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([t1,t1,t1],dim=1)) #[t1[0]*3,t1[1]*3,t1[0]*3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
